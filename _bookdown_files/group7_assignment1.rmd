---
title: "AEF_Assignment1 Group 07"
author: "Gian Waltert, Philipp Bößendörfer, Vladimir  Pajic"
date: "04/03/2022"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The Markdown files are used to test your knowledge on the subjects taught throughout week 1 of the Exercise and Lab sessions. Please fill the file such that you enter your answers in the respective code chunks below each question. If you require more code chunks to complete your assignment, please put the chunks in the correct position and indicate each chunk accordingly. 

**Deadline**

All deliverables have to be turned in on OLAT by **04th of March, 2022, 12.00 (noon) before class** the latest. Ensure that you submit the deliverables before the deadline, since late reports will receive a grade of 1.

**Deliverables**

- **R Markdown File**: Turn in the R-Markdown file including all your calculations and relevant comments for the code and the answers to the theoretical questions. The file should be named as followed: `groupname_assignment1.Rmd`

**Grading**

The grading of the assignment will be based on three main evaluation parts. 

1. Theoretical Knowledge and Accuracy of its implications 

In the first part, we will test your knowledge on the theoretical topics covered during the lecture and assess your ability to transfer the theoretical arguments to concrete use cases. This evaluation will be in form of intuition-and theory-based argumentation questions, which will either rely on statements derived from class or from quantitative outputs of related papers. You do not explicitly need to read the papers in order to comprehend the question. However, note that it is recommended to at least skim through it as it will also enhance your ability to solve the questions. Please answer the questions in the marked fields and use, whenever necessary, Latex language to convey your statements (e.g. use $\beta_i$ to indicate the i'th $\beta$ or use `$$...$$` to write an equation)

2. Application of the theory and Lab exercises

In the first exercise, we will only test your ability to apply some basic R functions in actual code. This assessment will be in form of coding-and-describing questions, which will rely to approximately 70% on the coding steps and concepts you can find in the **Bookdown** file, and to 30% on your own ability to enhance the provided code and advance the empirical steps we discussed during the Lab sessions. Note that **you can copy paste code we provide you with** to solve the exercises, but be aware that we may have **changed the inputs and procedures for some questions**, such that **simply copy pasting the code may sometimes result in an incorrect answer**. 

3. Design and Documentation 

The last part constitutes an evaluation of your overall ability to design and document code. Therein, we will assess both the theoretical and empirical part of your submission according to the design choices and extent of the documentation. That is, we will evaluate based on the (I) documentation of your coding steps, (II) structure of your code, (III) structure of the entire document, (IV) description of the theory questions as well as (V) design choices of your plots. We follow this approach because effective coding is not only correct, but also comprehensible and well documented. Consequently, writing with consistent and coherent designs of your code is a necessary prerequisite when working with multiple stakeholder groups and we want you to be able to mititgate potential irregularities that arise from individually written code. 

**Code and Copy**

As we already mentioned, you are allowed to copy paste code we provided you with as long as you ensure that this code is actually correct and adjusted to the question at hand. However, note that we want you to code on your own. This means that we neither want you to copy code you received from your peers that took the class in previous years nor copy it from peers that take it this year. In order to ensure a fair and transparent evaluation, we thus will run all your codes through a code copy identifier, which provides us with similarity scores for each code. If some similarity should be above a certain threshold, we will check the repsective assignments and, if we deem that there is a copy issue, we may address you directly. This is likely to be in form of a small oral assignment in which you are required to tell us all the code steps and how they relate to each other. Note that we don't want to punish you for cheating, but rather we want to to understand the code behind your solution. Consequently, even if you copied your code and we find out, you will have to look at the code again and try to comprehend it, fostering your knowledge either way :-)

**Materials**

We will provide you with a template for the exercise session. Further, we provide you with a comprehensive list of R packages. These packages will allow you to work on most of the tasks you will ever encounter in R and thus serve as a sound fundament for your future work. Note that although we do not require all the packages we provide you with, it nevertheless is handy to call all of the packages first such that you don't have to run into errands later on. 

```{r, comment=NA, include=FALSE, echo=FALSE}
packs.inst <- c("readxl","foreign","dplyr","tidyr","ggplot2","stargazer","haven","dummies","Hmisc",
           "lmtest","sandwich", "doBy", "multiwayvcov", "miceadds", 
           "car", "purrr", "knitr", "zoo", "readstata13", "tidyverse", "psych",
           "wesanderson", "lubridate","reporttools", "data.table", "devtools",
           "rmarkdown","estimatr", "ivpack", "Jmisc", "lfe", "plm", "tinytex", "xts", "psych", "PerformanceAnalytics",
           "roll", "rollRegres", "glmnet", "hdm", "broom", "RCurl", "learnr", "maps", "fGarch", "remotes", "RPostgreSQL", "wrds", "DBI", "RPostgreSQL", "remotes", "RPostgres", "Rmisc", "ggthemes", "splitstackshape", "gginference", "MASS")
packs.load <- c("fGarch")


#lapply(packs.inst, install.packages, character.only = FALSE) 

lapply(packs.inst, require, character.only = TRUE)
```

Remember that, if you have never installed any package before, you need to use the commented out function first. Further, if you encounter any issues while installing the packages, look which package rendered an error and exclude this package. Also note that, during the first installing process, it may take a while to get all the packages. 

# Data

On OLAT you will find *six different data sets* for the first assignment. You will need to use these datasets in order to tackle Exercise 9. The datasets are labeled as 

- **BigFour Dataset**

This data set contains the historical prices of the big four companies (Nestle, Novartis, Roche and UBS). You should use this dataset to calculate time-series returns in an xts object. 


- **A1_dataset_01 - A1_dataset_05**

- These are five randomly generated datasets with 33 x and y observations. You should use this dataset for Exercise 9. 

# Controls and Hints

Below you find sample solutions for certain values to check your work progress and make sure that you are on the right track: 


# Exercise 1: R Markdown files - Handling of code chunks and white spaces in Latex style 

In the first exercise, you will work with the R markdown file. Therein, we ask you to perform preliminary steps in order to better understand how to work with both code chunks and the white spaces. Further, you will be asked to work on your Latex style grammar. 

## Adjust the text below such that: 

- The first sentence is written in italic
- The second sentence is written in in bold
- The third sentence is written underlined
- The first word in the fourth sentence is given as verbatim
- The words defined as (I), (II) etc. of the fifth sentence are given in an enumeration 

Text: 

\textit{White spaces are the spaces you are currently reading this text.} \textbf{They serve as string-based Chunks, meaning that you can write human language based sentences within these cells.} \underline{They are one of the two main methods to write something into R Markdown.} `Codechunks ` are the other form of writing into word. White spaces serve as areas for writing
\begin{enumerate} \item[(I)] results of reports \item[(III)] explanations, \item[(IV)] formulas or  \item[(V)] in general everything that has no code-based output at the end. \end{enumerate}

## Adjust the code chunk settings

For the following code chunk:

- change both the figure width to 3 and the figure height to 2.3
- change the alignment to center

Further, change the code chunk such that:

- R hides the code in the output
- prevents messages and warnings from appearing in the finished file

```{r, fig.width=3, fig.height=2.3, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}
plot(datasets::swiss$Fertility, datasets::swiss$agriculture)
```

## Write the formula for the Normal Distribution with Dollar Signs around it (= $$...$$)

[The Normal Distribution is defined as ](https://www.thoughtco.com/normal-distribution-bell-curve-formula-3126278)

$$
y = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\
\mu=\mbox{Mean} \\
\sigma=\mbox{Standard Deviation} \\
\pi \approx 3.14159... \\
e \approx 2.71828...
$$


## Write the proof of a function with the "align" method

Go to the [following website](http://sp-finance.e-monsite.com/pages/important-concept/mathematical-concepts/ito-s-lemma.html). Search for the sentence:

- **is of order dt, it does not integrate to zero and must remain in the equation.** on the website of the link.

Below this sentence you will find one part of the proofs for Ito's Lemma, which is used for the Brownian Motion (it is a proof starting with df = ... and has 5 rows overall). 

You are now asked to write the proof in latex format. Remember that you need to use the $$...$$ signs and the "align" method: 

$$
\begin{align}
df \quad & = \quad \frac{\partial f}{\partial X_t}dX_t + \frac{\partial f}{\partial t}dt + \frac{1}{2}\frac{\partial^2f}{\partial X^2_t}(dX_t)^2 \\
  & = \quad \frac{\partial f}{\partial X_t}(a_tdt+b_tdW_t) + \frac{\partial f}{\partial t}dt \\
  & \qquad + \frac{1}{2}\frac{\partial^2f}{\partial X^2_t}(a_tdt+b_tdW_t)^2 \\
  & = \quad \left( \frac{\partial f}{\partial X_t}a_t + \frac{\partial f}{\partial t}+ \frac{1}{2}\frac{\partial^2f}{\partial X^2_t}b^2_t \right)dt \\
  & \qquad + \frac{\partial f}{\partial X_t}b_tdW_t.
  
\end{align}
$$

# Exercise 2: Vectors 

## Create a vector of three elements (1,5,8) and name that vector `vec_a`. Create a second vector, `vec_b`, that contains (6,7,11). Add these two vectors together and name the result `vec_c`. 

```{r}
vec_a <- c(1,5,8) # create vector a
vec_b <- c(6,7,11) # create vector b

vec_c <- vec_a + vec_b # add vectors a and b to create vector c
str(vec_c) # output vector c
```

## Create a vector, named `vec_d`, that contains only two elements (14,18). Add this vector to `vec_a`. What is the result and what do you think R did? What is the warning message that R gives you?

```{r}
vec_d <- c(14,18) # create new vector d

vec_a + vec_d # add both vectors together
```

The error message R provided was that the longer vector, in our case a, was not a multiple of the shorter vector d. The result of adding `vec_d` to `vec_a` is the vector c(15,23,22). It seems as though R performed a regular vector addition on the first two entries in `vec_a` and then added the first entry in `vec_d` to the third entry in `vec_a`.

## Generate the vector of integers: {3,6,...,30}  in two different ways:

- First using the `seq()` function
- Using the `a:b` shortcut and subsequent algebra

```{r}
seq(from=3, to=30, by=3) # create vector by using seq() function

Filter(function(x) x %% 3 == 0, 3:30) # create vector by using 3:30 and filtering entries not divisible by 3
```

## Generate the vector  {2,4,8,2,4,8,2,4,8} using the rep() command to repeate the vector c(2,4,8)

```{r}
rep(c(2,4,8), 3) # replicate vector (2,4,8) 3 times
```

## The vector letters is a built-in vector to R and contains the lower case English alphabet.

- Extract the 11th element of the letters vector.
- Extract the sub-vector that contains the 9th, 12th, and 22nd elements.
- Extract the sub-vector that contains everything except the last two elements and the fifth element

```{r}
letters[11] # extract 11th element
letters[c(9,12,22)] # extract the 9th, 12th, and 22nd elements
letters[-c(5,25,26)] # extract everything, except for the 5th, 25th, and 26th element
```

# Exercise 3: Matrices and Data Frames

## Matrices

Work with the following matrix: 

$$
M= 
\begin{bmatrix}
1 & 8 & 7 & 18 & 10\\
3 & 5 & 44 & 7& 16 \\
5& 3 & 12 & 3 & 6  
\end{bmatrix}
$$

### Create the matrix in two ways and save the resulting matrix as M:

- Create the same matrix by either the rbind() or cbind() command.

```{r}
M <- rbind(c(1,8,7,18,10), c(3,5,44,7,16), c(5,3,12,3,6)) # create matrix M with rbind
str(M) # create output
```

### Use the matrix for manipulation: 

- Extract the second element of the third column

```{r}
M[2,3]
```

- Extract the last row 

```{r}
M[3,]
```

- Extract all even numbers

```{r}
M[subset(M %% 2 == 0)] # extract even numbers from M by using modulo operator
```


## Data Frames

## Create the following data frame:

  - Company: ABB, Nestle, Roche, Novartis, UBS, Credit Suisse, Actelion
  - ROE: 0.12, 0.21, 0.04, 0.32, 0.10, 0.23, 0.24
  - Rating: AAA, AA, AAA, AA+, BB, BBB, CC
  - Size: 200, 1800, 1124, 1341, 1211, 900, 123
  
```{r}
df <- data.frame(
  Company = c("ABB", "Nestle", "Roche", "Novartis", "UBS", "Credit Suisse", "Actelion"),
  ROE = c(0.12, 0.21, 0.04, 0.32, 0.10, 0.23, 0.24),
  Rating = c("AAA", "AA", "AAA", "AA+", "BB", "BBB", "CC"),
  Size = c(200, 1800, 1124, 1341, 1211, 900, 123)
) # create data frame

df # create output
```

### Extract the third observation (i.e. the third row)

```{r}
df[3,]
```

### Create an order that orders the rating column according to: AAA - AA+ - AA - BB - BBB - CC

```{r}
sort <- c("AAA", "AA+", "AA", "BB", "BBB", "CC") # create sorting vector that defines the order
df <- df %>% arrange(factor(Rating, levels = sort)) # sort our data frame by Rating according to the order we specified in or sorting vector

df # create output

```

### Print out a data frame of all the observations except for the fourth observation. (i.e. Remove the fourth row.)

```{r}
df[-4,]
```

###  Use the `which()` command to create a vector of row indices that have a size greater than or equal to 1000. Call that vector Sufficient_Rating (= dummy variable)

```{r}
Sufficient_Rating <- which(df$Rating<"BB") # row indices with size greater or equal to AA

df <- df %>% mutate(Sufficient_Rating = ifelse(df$Rating<"BB", 1,0)) # create a dummy variable for the Sufficient Size used in later exercise
```


### Create a dummy variable with the `ifelse()` command that indicates 1 if the size is above the mean and 0 else

```{r}
df <- df %>% mutate(Size_Dummy = ifelse(Size > mean(Size, na.rm = T), 1,0)) # create dummy variable for size above the mean
```

### Get the average size of the companies for which both dummies are 1 (above mean size and rating greater than or equal to AA)

```{r}
mean(df$Size[which(df$Size_Dummy==1 & df$Sufficient_Rating == 1)]) # calculate mean of size for Ratings AA and above, as well size above the mean
```


# Exercise 4: Importing Data

1. Get the Swiss Fertility and Socioeconomic Indicators (1888) Dataset. Google it and try to get the correct R package which includes the dataset, by using: `specific_package_name::swiss`. Note the specific_package_name needs to be changed with the actual package name. 

```{r}
swiss_data <- datasets::swiss # get swiss fertility data
```

2. Calculate the average fertility rate for all communes under consideration if the education level is above 7. 

```{r}
mean(swiss_data$Fertility[swiss_data$Education > 7]) # calculate average fertility when education is above 7
```

# Exercise 4: Data Manipulation

In this part, we want you to work in the `dplyr` way that we showed you during the first exercise session. Please refer to the section in the bookdown if you have any questions as how to write the code in the appropriate fashion.  

## Get and load the dataset on `UScrime` from the `MASS()` package and assign a name to it

```{r}
crime_data <- MASS::UScrime
```

## Select all except the columns Po1 and M.F. Assign a name to this shrunken data frame

```{r}
small_crime_data <- crime_data %>% dplyr::select(-c(Po1, M.F))
```

## Print all rows for which Pop is below 50 and NW is above 100

```{r}
small_crime_data %>% dplyr::filter(Pop<50 & NW>100)
```

## Order the dataframe according to the first column - but in descending format

```{r}
small_crime_data %>% dplyr::arrange(desc(small_crime_data[,1]))
```

## Create a new variable that multiplies the column So with Ed and create in the same code a new column that assigns a 2 if Ed is above 90 and a 0 otherwise

```{r}
small_crime_data <- small_crime_data %>%  mutate(Multiply = So*Ed, Ed_Indicator = ifelse(Ed > 90, 2, 0))
```

## Now, perform some further manipulation strategies simultaneously

- 1) Select all except for the "So", "Prob" and "y" column
- 2) Filter according to population below 50, GDP above 400 and Ineq below the median value
- 3) Create another dummy variable that assigns a 1 if LF is above the mean value and a 0 otherwise
- 3) Group by this dummy variable
- 4) Create variables for the max, min and mean values of the column "Ed" for each group

```{r}
small_crime_data %>%
  dplyr::select(-c("So", "Prob", "y")) %>% # 1) Select all except for the "So", "Prob" and "y" column
  dplyr::filter(Pop<50 & GDP>400 & Ineq<median(Ineq, na.rm = T)) %>% # 2) Filter according to population below 50, GDP above 400 and Ineq below the median value
  mutate(Dummy = ifelse(LF > mean(LF, na.rm = T), 1,0)) %>% # 3) Create another dummy variable that assigns a 1 if LF is above the mean value and a 0 otherwise
  group_by(Dummy) %>% # 4) Group by this dummy variable
  mutate(max_ed = max(Ed), min_ed = min(Ed), mean_ed = mean(Ed)) # 5) Create variables for the max, min and mean values of the column "Ed" for each group
```

# Exercise 5: GGPlot

##  Get and load the dataset on `UScrime` from the `data()` package. 

```{r}
crime_data <- MASS::UScrime # data() package doesn't exist for this version of R, but the data is from MASS()
```

## Create a histogram of the column Ineq

```{r}
crime_data %>% ggplot(aes(x=Ineq)) +
  geom_histogram(bins = 10) # changed bin size from 30 for better visualization
```

## Plot a scatterplot of NW and Ineq 

```{r}
crime_data %>% ggplot(aes(x=NW, y = Ineq)) +
  geom_point()
```

## Distinguish the scatterplot between So = 1 and So = 0s with the `color` argument

```{r}
crime_data$So = as.factor(crime_data$So) # change So dummy variable to categorical value
crime_data %>% ggplot(aes(x=NW, y = Ineq, color=So)) + # create plot
  geom_point()
```

## Add a linear line to the plot 

```{r}
crime_data %>% ggplot(aes(x=NW, y = Ineq)) +
  geom_point() +
  geom_smooth(method = "lm", se= FALSE) # add linear line without SE, not sure what kind of linear line is meant so we added a linear regression fit
```

## Calculate the mean and 95% CI values for Ineq depending on So. Plot an errorbar as we did in the exercise session with the mean value for Ineq as well as a ribbon indicating the 95% CI for So = 0 and So = 1

```{r}
crime_data <- crime_data%>% dplyr::group_by(So) %>% mutate(mean=mean(Ineq))
crime_data <- crime_data %>% dplyr::group_by(So) %>% 
  dplyr::mutate(mean_ineq=mean(Ineq)) %>%# add the mean and the 95% CI to the dataset
  dplyr::mutate(sd_ineq=sd(Ineq)) %>%
  dplyr::mutate(low_ineq=mean_ineq-1.96*sd_ineq) %>% # create the lower bound of the 95% CI
  dplyr::mutate(upper_ineq=mean_ineq+1.96*sd_ineq) # create the upper bound of the 95% CI
crime_data %>% ggplot(aes(x = So)) + # create and format the graph
  geom_errorbar(aes(ymin=low_ineq, ymax=upper_ineq)) + 
  geom_point(aes(y = mean_ineq), col = "blue", size=3, shape=21, fill="white")

```

## Melt the Po1 and Po2 columns. Plot a density plot for the variables as we did in the lecture

```{r}
Po <- crime_data[,c("Po1","Po2")] # extract Po1 and Po2 from data frame
melt_Po<- melt(as.data.table(Po)) # melt Po1 and Po2 as a data table

melt_Po %>% ggplot(aes(x = value, fill = variable)) + # graph density plot
  geom_density(alpha = 0.2)
```

## Make a facet grid plot of NW and Ineq. Do this based on 1) So and 2) on a variable you create that splits GDP into 4 groups. For this, use the `cut()` function with the following command: `mutate( GDP_Groups = cut(GDP, breaks = c(318, 420, 550, 689))`

```{r}
crime_data <- crime_data %>% mutate(GDP_Groups = cut(GDP, breaks = c(318, 420, 550, 689))) # create GDP groups, note that we only have three meaningful GDP groups as the last group, "NA", is not contained in any of the intervals since we are considering one-sided closed intervals.

crime_data %>% ggplot(aes(x = NW, y = Ineq)) + # create facet grid
  geom_point() + 
  # define that it should print the same relation just for each So and GDP group separately
  facet_grid(GDP_Groups ~ So) 
```

## Now make the plot that you created with the geom_point and the linear line pretty. That is, orientate yourself on the design principles and code we provided you with and make a nice looking plot

```{r}
crime_data %>% ggplot(aes(x=NW, y = Ineq, color = So)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_color_manual(values=c("goldenrod", "darkorchid4", "darkorange2","dodgerblue1", "springgreen2",  "darkorchid4", "dodgerblue4"))  +
  scale_fill_manual(values=c("goldenrod", "darkorchid4", "darkorange2","dodgerblue1", "springgreen2",  "darkorchid4", "dodgerblue4")) +
  # X and Y axis string
  ylab("Ineq") + xlab("NW") + 
  # Title string
  ggtitle("Relationship of Ineq and NW") +
  labs(color='So') +
  theme(
  # Title Elements
  plot.title= element_text(size=14, color="grey26", hjust=0.5,lineheight=0.4, margin=margin(15,0,15,0)), 
  # Axis Elements
  axis.title.y = element_text(color="grey26", size=12, margin=margin(0,10,0,10)),
  axis.title.x = element_text(color="grey26", size=12, margin=margin(10,0,10,0)),
  # Background colour and fill
  panel.background = element_rect(fill="#f7f7f7"),
  plot.background = element_rect(fill="#f7f7f7", color = "#f7f7f7"),
  # Major Panel Grids
  panel.grid.major.x = element_blank(),
  panel.grid.major.y = element_line(size = 0.5, linetype = "solid", color = "grey"),
  # Minor Panel Grids
  panel.grid.minor.x = element_blank(),
  panel.grid.minor.y = element_blank(),
  # Line colour of the x and y axis
  axis.line = element_line(color = "grey")) 

```

# Exercise 6: Date and Times

## For the following formats for a date, transform them into a date/time object. Which formats can be handled nicely and which are not?

```{r}
birthday <- c(
  'May 31st, 1996',
  'May 31, 1996',
  'Sep 13, 1978',
  '5-31-96',
  '5/31/96', 
  '31. Mai 1996')
```

```{r}
mdy(birthday)
```

The entries 1-5 can be handled nicely, as they all follow the same Month-Day-Year format. The last entry, however, is in a Day-Month-Year format and the month name is written in German. Therefore, this needs special consideration.

## Time and Date: For the following data, create the correct US date and time format:

```{r}
date_time <- c("31st May 1996 16:05:11", "31.05.1996 16:05:11", "31 May 96 16:05:11", "31 May 1996 16:05:11", "31-5-96 16:05:11", "31-5-1996 16:05:11")
```

```{r}
date_time <- dmy_hms(date_time) # create date/time objects
format(date_time, "%m/%d/%Y %I:%M:%S")  # format dates according to m/d/y and 12-hour time in the US
```

## For the data above, just take the date, but leave the time out

```{r}
format(date_time, "%D") # produces only the date, without time
```

# Exercise 7: Time Series Data

Load the data on the big four companies that we have provided you with. For this dataset: 

## Transform the dataset into an xts object 

```{r}
B4 <- read.csv("/Users/gian/Desktop/AEF/Assignment 1/Data/A1_bigfour.csv", header = T) # import dataset

B4_date <- as.Date(dmy(B4$Date)) # use a date column

B4_ts <- xts(B4[,-1], order.by = B4_date) # data is transformed into an xts object
```

## Calculate a lag value for each time-series column. Write down quickly why we should use the command `stats::lag()` when we want to define a lagged value. 

```{r}
lag <- stats::lag(B4_ts) # create a lag column
lag[1:5,] # output the first 5 entries
```

It is important to use the command stats::lag() because the dplyr package also has a lag() function and because it is the higher ranked package, R will automatically choose the dplyr function if we do not specify the stats package. Since the dplyr lag function cannot be rendered, we need to specify that we want to take the lag function explicitly from the stats package.

# Exercise 8: 

## The following file names were used in a camera trap study. The S number represents the site, P is the plot within a site, C is the camera number within the plot, the first string of numbers is the YearMonthDay and the second string of numbers is the HourMinuteSecond.

```{r}
file.names <- c( 'S123.P2.C10_20120621_213422.jpg',
                 'S10.P1.C1_20120622_050148.jpg',
                 'S187.P2.C2_20120702_023501.jpg')
```

Use a combination of `str_sub()` and `str_split()` to produce a data frame with columns corresponding to the *site, plot, camera, year, month, days, hour, minute, and second* for these three file names. So we want to produce code that will create the data frame:

$$
\begin{pmatrix}
Site & Plot & Camera & Year & Month & Day & Hour & Minute & Second \\
S123  & P2   & C10 &2012  &  06  &21   &21  &   34   &  22\\
S10  & P1   &  C1 &2012   & 06 & 22  & 05  &   01   &  48\\
S187&   P2   &  C2 &2012  &  07&  02 &  02  &   35  &   01
\end{pmatrix}
$$

```{r}

site <- c(str_split_fixed(file.names, "[.]", n=4)[,1]) # everything before the first "." is the site
plot <- c(str_split_fixed(file.names, "[.]", n=4)[,2]) # everything between the first and the second "." is the plot
camera <- c(str_split_fixed(str_split_fixed(file.names, "[.]", n=4)[,3], "_", n=3)[,1]) # between the second "." and the first "_" is the camera
year <- str_sub(c(str_split_fixed(str_split_fixed(file.names, "[.]", n=4)[,3], "_", n=3)[,2]), start = 1, end = 4) # first 4 numbers after first "_"
month <- str_sub(c(str_split_fixed(str_split_fixed(file.names, "[.]", n=4)[,3], "_", n=3)[,2]), start = 5, end = 6) # numbers 5-6 after first "_"
day <- str_sub(c(str_split_fixed(str_split_fixed(file.names, "[.]", n=4)[,3], "_", n=3)[,2]), start = 7, end = 8) # numbers 7-8 after first "_"
hour <- str_sub(c(str_split_fixed(str_split_fixed(file.names, "[.]", n=4)[,3], "_", n=3)[,3]), start = 1, end = 2) # numbers 1-2 after second "_"
minute <- str_sub(c(str_split_fixed(str_split_fixed(file.names, "[.]", n=4)[,3], "_", n=3)[,3]), start = 3, end = 4) # numbers 3-4 after second "_"
second <- str_sub(c(str_split_fixed(str_split_fixed(file.names, "[.]", n=4)[,3], "_", n=3)[,3]), start = 5, end = 6) # numbers 5-6 after second "_"

# create data frame with the values created above
df <- data.frame(
  Site = site,
  Plot = plot,
  Camera = camera,
  Year = year,
  Month = month,
  Day = day,
  Hour = hour,
  Minute = minute,
  Second = second
)

df
```

# Exercise 9: Loading multiple datasets with paste and assign

## Now, we want to load different datasets and assign them distinct names. For that, use the 5 distinct csv files we provide you with, called: `A1_dataset_01` to `A1_dataset_05`. Load each of the files and assign them the names `Data1` to `Data5` in the R environment. 

```{r}
data_names <- c("A1_dataset_01", "A1_dataset_02", "A1_dataset_03", "A1_dataset_04", "A1_dataset_05") # create vector with names of data files

for (i in 1:length(data_names)){ # loop through data files
  
  paste0(assign(paste0("Data", i), read.csv(paste0("/Users/gian/Desktop/AEF/Assignment 1/Data/", data_names[i], ".csv"), sep = ","))) # for each data file, read the appropriate csv file and assign the name "Data + # of file"

}
```

## Now, plot a scatterplot of the x and y variable for each of the distinct dataframes. Also follow the for loop logic we discussed in the Bookdown. 

```{r}
data_names <- c("Data1", "Data2", "Data3", "Data4", "Data5") # create vector with data names
data_files <- list(Data1, Data2, Data3, Data4, Data5) # create list with data files

for (i in 1:length(data_files)){  assign(paste("figure_",data_names[i],sep = ""), # Here, we define the name  for each created ggplot

  data_files[[i]] %>% # here we create the scatter plots
    ggplot(aes(x=x,y=y)) + 
    geom_point() +
    ggtitle(paste("Figure for",data_names[i],sep = " ")) +
    theme(
          # Title Elements
          plot.title = element_text(size=14, color="grey26", hjust=0.5,lineheight=0.4, margin=margin(15,0,15,0)),
          # Background
          panel.background = element_rect(fill="#f7f7f7"),
          plot.background = element_rect(fill="#f7f7f7", color = "#f7f7f7"),
          # Major Panel Grids
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_line(size = 0.5, linetype = "solid", color = "grey"),
          # Minor Panel Grids
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          # Line color of the x and y axis
          axis.line = element_line(color = "grey")
          ))
  
}

# display the plots
figure_Data1 
figure_Data2
figure_Data3
figure_Data4
figure_Data5

```
